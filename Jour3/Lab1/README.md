# LAB 3.1 â€” Pipeline robuste Taxi

## ğŸ¯ Objectif pÃ©dagogique

Construire un pipeline Apache Hop robuste pour :

- Ingestion dâ€™un dataset Taxi (CSV)
- Nettoyage des donnÃ©es
- Validation des champs critiques
- Rejet des lignes invalides
- SÃ©paration des flux "clean" et "errors"

Ã€ la fin du lab vous devrez comprendre comment structurer un pipeline industriel, gÃ©rer les erreurs et rendre un pipeline rejouable.

## ğŸ§  Contexte

Nous travaillons sur un extrait du dataset NYC Taxi. Certaines lignes peuvent contenir :

- valeurs nulles
- dates incohÃ©rentes
- montants nÃ©gatifs
- coordonnÃ©es invalides

Votre mission est de construire un pipeline qui nettoie, valide, sÃ©pare et exporte les donnÃ©es conformÃ©ment Ã  la structure de dossiers ciâ€‘dessous.

## ğŸ“‚ Structure attendue

data/
â”œâ”€â”€ raw/
â”œâ”€â”€ clean/
â””â”€â”€ rejected/

Exemples de chemins relatifs au projet : `TP/Jour3/Lab1/data/raw/`, `TP/Jour3/Lab1/data/clean/`, `TP/Jour3/Lab1/data/rejected/`.

## ğŸ§ª Ã‰tapes dÃ©taillÃ©es

1) Ingestion CSV

- CrÃ©er un nouveau pipeline Hop.
- Ajouter une Ã©tape `CSV File Input`.
- Lire le fichier depuis `data/raw/`.
- VÃ©rifier l'encodage, le sÃ©parateur et le mapping des colonnes.

2) Typage & Normalisation

- Ajouter `Select Values` pour caster les types.
- Utiliser `Date format` et `Number format` si nÃ©cessaire.
- Champs critiques Ã  vÃ©rifier : `pickup_datetime`, `dropoff_datetime`, `total_amount`, `passenger_count`.

3) RÃ¨gles de validation

- Ajouter une Ã©tape `Filter Rows` (ou Ã©quivalent).
- RÃ¨gles recommandÃ©es :
  - `total_amount > 0`
  - `passenger_count > 0`
  - `pickup_datetime` NOT NULL
  - `dropoff_datetime` NOT NULL
- SÃ©parer les flux :
  - Flux valide -> vers `clean`
  - Flux invalide -> vers `rejected`

4) Gestion dâ€™erreur

- Activer lâ€™`Error handling` sur les transformations critiques.
- Capturer les lignes qui Ã©chouent et enrichir chaque ligne rejetÃ©e avec une colonne `error_reason` expliquant la cause (ex : `missing_pickup_datetime`, `negative_amount`).

5) Export

- Flux valide : `CSV Output` â†’ `data/clean/taxi_clean.csv`
- Flux invalide : `CSV Output` â†’ `data/rejected/taxi_rejected.csv`

## ğŸ”§ Bonnes pratiques

- Rendre le pipeline idempotent et rejouable :
  - utiliser `batch_id` et `processing_timestamp` pour chaque enregistrement
  - Ã©crire dans des fichiers horodatÃ©s ou Ã©craser de maniÃ¨re contrÃ´lÃ©e
- Journaliser les erreurs et mÃ©triques (nombre de lignes traitÃ©es / rejetÃ©es).
- Tester le pipeline avec Ã©chantillons (cas limitÃ©s, cas limites, donnÃ©es corrompues).

## ğŸ” Questions de rÃ©flexion

- Que se passe-t-il si une colonne change de nom ?
  - prÃ©voir un mapping de colonnes configurable, ou valider l'en-tÃªte avant ingestion.
- Que se passe-t-il si le fichier contient 10 millions de lignes ?
  - envisager un traitement par lots, streaming, partitionnement, et monitoring mÃ©moire/IO.
- Votre pipeline est-il rejouable ?
  - oui si les sorties sont dÃ©terministes, si l'on gÃ¨re les IDs de batch et si l'on Ã©vite les opÃ©rations non-dÃ©terministes sans checkpoint.

## ğŸ“ Bonus (optionnel)

- Ajouter automatiquement une colonne `processing_timestamp` (timestamp d'exÃ©cution).
- Ajouter une colonne `batch_id` (UUID ou date/heure) pour tracer un lot.

## âœ… Validation finale

Le pipeline doit :

- Ne jamais planter (s'assurer d'un error handling robuste)
- SÃ©parer `clean` et `rejected`
- ÃŠtre clair visuellement (noms d'Ã©tapes explicites)
- ÃŠtre documentÃ© (ce README + commentaires dans le pipeline)

---

Placez ce README dans le rÃ©pertoire du lab : `TP/Jour3/Lab1/README.md`.

Bon travail â€” dites-moi si vous voulez que je gÃ©nÃ¨re un exemple de pipeline Hop ou un template XML pour dÃ©marrer.
